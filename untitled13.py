# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FnM1L1X-XPaMtTkDuf8rqCzVG5avNbP3

## Project Title - Local Food Wastage Management System

# Skills take away From This Project -
●	Python

●	SQL

●	Streamlit

●	Data Analysis

# Github Link -

# Problem Statement - Food wastage is a significant issue, with many households and restaurants discarding surplus food while numerous people struggle with food insecurity. This project aims to develop a Local Food Wastage Management System, where:
●	Restaurants and individuals can list surplus food.

●	NGOs or individuals in need can claim the food.

●	SQL stores available food details and locations.

●	A Streamlit app enables interaction, filtering, CRUD operation and visualization.

# Start -

# Data preparation -
●	Utilize a provided dataset containing food donation records.

●	Ensure consistency and accuracy in data formatting.
"""

# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# upload all csv
from google.colab import files
uploaded = files.upload()

# Load datasets to DataFrames
claims = pd.read_csv("claims_data.csv")
food = pd.read_csv("food_listings_data.csv")
receivers = pd.read_csv("receivers_data.csv")
providers = pd.read_csv("providers_data.csv")

# Standerdize column name
datasets = [claims, food, receivers, providers]
for df in datasets:
    df.columns = df.columns.str.strip().str.replace(" ", "_")

# Convert Date columns
claims['Timestamp'] = pd.to_datetime(claims['Timestamp'], errors='coerce')
food['Expiry_Date'] = pd.to_datetime(food['Expiry_Date'], errors='coerce')

# Ensure Correct Data Types
# IDs as integers
id_cols = ['Claim_ID', 'Food_ID', 'Receiver_ID', 'Provider_ID']
for col in id_cols:
    for df in datasets:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer')

# Quantities as integers
if 'Quantity' in food.columns:
    food['Quantity'] = pd.to_numeric(food['Quantity'], errors='coerce', downcast='integer')

# Clean String Fields
def clean_text_columns(df):
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].astype(str).str.strip().str.title()

for df in datasets:
    clean_text_columns(df)

# Check Missing Values
for name, df in zip(["Claims", "Food", "Receivers", "Providers"], datasets):
    print(f"\nMissing values in {name} dataset:")
    print(df.isnull().sum()[df.isnull().sum() > 0])

# Validate Foreign Keys
missing_food_ids = set(claims['Food_ID']) - set(food['Food_ID'])
missing_receiver_ids = set(claims['Receiver_ID']) - set(receivers['Receiver_ID'])
missing_provider_ids = set(food['Provider_ID']) - set(providers['Provider_ID'])

print("Missing Food IDs in claims:", missing_food_ids)
print("Missing Receiver IDs in claims:", missing_receiver_ids)
print("Missing Provider IDs in food:", missing_provider_ids)

# Optional: Drop rows with broken links
claims = claims[claims['Food_ID'].isin(food['Food_ID'])]

# Merge Datasets into One Master Table
master = (claims
          .merge(food, on="Food_ID", how="left", suffixes=('', '_food'))
          .merge(providers, on="Provider_ID", how="left", suffixes=('', '_provider'))
          .merge(receivers, on="Receiver_ID", how="left", suffixes=('', '_receiver'))
         )

# Add Helper Columns
master['Days_To_Expiry'] = (master['Expiry_Date'] - master['Timestamp']).dt.days
master['Is_Expired'] = np.where(master['Days_To_Expiry'] < 0, 1, 0)

# Save the Clean Dataset
master.to_csv("clean_master_dataset.csv", index=False)
print("✅ Clean dataset saved as clean_master_dataset.csv")

"""# Database Creation"""

import sqlite3

conn = sqlite3.connect('food_wastage.db')

cursor = conn.cursor()
conn.execute('''
-- Table for claims_data
CREATE TABLE claims_data (
    Claim_ID INTEGER PRIMARY KEY,
    Food_ID INTEGER,
    Receiver_ID INTEGER,
    Status TEXT,
    Timestamp TEXT
);
''')
conn.commit()
print ('claims_data table created successfully')

cursor = conn.cursor()
conn.execute('''
   -- Table for food_listings_data
CREATE TABLE food_listings_data (
    Food_ID INTEGER PRIMARY KEY,
    Food_Name TEXT,
    Quantity INTEGER,
    Expiry_Date TEXT,
    Provider_ID INTEGER,
    Provider_Type TEXT,
    Location TEXT,
    Food_Type TEXT,
    Meal_Type TEXT
);
''')
conn.commit()
print ('food_listings_data table created successfully')

cursor = conn.cursor()
conn.execute('''
-- Table for providers_data
CREATE TABLE providers_data (
    Provider_ID INTEGER PRIMARY KEY,
    Name TEXT,
    Type TEXT,
    Address TEXT,
    City TEXT,
    Contact TEXT
);
''')
conn.commit()
print ('providers_data table created successfully')

cursor = conn.cursor()
conn.execute('''
     -- Table for receivers_data
CREATE TABLE receivers_data (
    Receiver_ID INTEGER PRIMARY KEY,
    Name TEXT,
    Type TEXT,
    City TEXT,
    Contact TEXT
    );
''')
conn.commit()
print ('receivers_data table created successfully')

# Import data from DataFrames into SQLite tables
claims.to_sql('claims_data', conn, if_exists='replace', index=False)
food.to_sql('food_listings_data', conn, if_exists='replace', index=False)
receivers.to_sql('receivers_data', conn, if_exists='replace', index=False)
providers.to_sql('providers_data', conn, if_exists='replace', index=False)

print("✅ Data imported into SQLite database successfully")

import pandas as pd
import sqlite3

# Connect to the SQLite database
conn = sqlite3.connect('food_wastage.db')

# Define the CSV files and corresponding table names
files_tables = {
    'claims_data.csv': 'claims_data',
    'food_listings_data.csv': 'food_listings_data',
    'receivers_data.csv': 'receivers_data',
    'providers_data.csv': 'providers_data'
}

# Import each CSV into its corresponding table
for csv_file, table_name in files_tables.items():
    try:
        # Read the CSV file into a pandas DataFrame
        df = pd.read_csv(csv_file)

        # Insert the data into the SQLite table
        # if_exists='append' will add new rows. Use 'replace' to clear and insert anew.
        df.to_sql(table_name, conn, if_exists='append', index=False)
        print(f"Successfully imported {csv_file} into {table_name}")
    except FileNotFoundError:
        print(f"Error: {csv_file} not found.")
    except Exception as e:
        print(f"An error occurred while importing {csv_file}: {e}")

# Close the database connection
conn.close()

# Assume 'conn' and 'cursor' are already defined from previous cells
# If not, you would need to re-establish the connection:
# import sqlite3
# conn = sqlite3.connect('food_wastage.db')
# cursor = conn.cursor()
# Show all pending claims and their food type
cursor.execute('''
SELECT c.Claim_ID, f.Food_Name, f.Food_Type, c.Timestamp
FROM claims_data c
JOIN food_listings_data f ON c.Food_ID = f.Food_ID
WHERE c.Status = 'Pending'
''')

# Fetch and display the results
results = cursor.fetchall()

# Print the results (you might want to format this better for large results)
for row in results:
    print(row)

# Close the connection when you are completely done with database operations
# conn.close() # Uncomment this line if you want to close the connection here

# Assume 'conn' and 'cursor' are already defined from previous cells
# If not, you would need to re-establish the connection:
# import sqlite3
# conn = sqlite3.connect('food_wastage.db')
# cursor = conn.cursor()

# Find providers by city
cursor.execute("SELECT * FROM providers_data WHERE City = 'New Jessica'")

# Fetch and display the results
results = cursor.fetchall()

# Print the results
for row in results:
    print(row)

# Close the connection if you are completely done with database operations
# conn.close() # Uncomment this line if you want to close the connection here

# Assume 'conn' and 'cursor' are already defined from previous cells
# If not, you would need to re-establish the connection:
# import sqlite3
# conn = sqlite3.connect('food_wastage.db')
# cursor = conn.cursor()

# List foods expiring before March 20, 2025
cursor.execute('''
SELECT Food_ID, Food_Name, Expiry_Date
FROM food_listings_data
WHERE Expiry_Date < '3/20/2025'
''')

# Fetch and display the results
results = cursor.fetchall()

# Print the results
for row in results:
    print(row)

# Close the connection if you are completely done with database operations
# conn.close() # Uncomment this line if you want to close the connection here

# Assume 'conn' and 'cursor' are already defined from previous cells
# If not, you would need to re-establish the connection:
# import sqlite3
# conn = sqlite3.connect('food_wastage.db')
# cursor = conn.cursor()

# Count completed claims per receiver
cursor.execute('''
SELECT r.Name, COUNT(c.Claim_ID) AS Completed_Claims
FROM claims_data c
JOIN receivers_data r ON c.Receiver_ID = r.Receiver_ID
WHERE c.Status = 'Completed'
GROUP BY r.Name
''')

# Fetch and display the results
results = cursor.fetchall()

# Print the results
for row in results:
    print(row)

# Close the connection if you are completely done with database operations
# conn.close() # Uncomment this line if you want to close the connection here

# Assume 'conn' and 'cursor' are already defined from previous cells
# If not, you would need to re-establish the connection:
# import sqlite3
# conn = sqlite3.connect('food_wastage.db')
# cursor = conn.cursor()

# All claims linked to a specific provider
cursor.execute('''
SELECT c.Claim_ID, f.Food_Name, p.Name AS Provider_Name
FROM claims_data c
JOIN food_listings_data f ON c.Food_ID = f.Food_ID
JOIN providers_data p ON f.Provider_ID = p.Provider_ID
WHERE p.Name = 'Gonzales-Cochran'
''')

# Fetch and display the results
results = cursor.fetchall()

# Print the results
for row in results:
    print(row)

# Close the connection if you are completely done with database operations
# conn.close() # Uncomment this line if you want to close the connection here

import pandas as pd

# Load CSV data
claims_df = pd.read_csv("claims_data.csv")
food_df = pd.read_csv("food_listings_data.csv")
receivers_df = pd.read_csv("receivers_data.csv")
providers_df = pd.read_csv("providers_data.csv")

# CREATE - Add new record
def add_record(df, record):
    # Use pd.concat instead of append
    new_record_df = pd.DataFrame([record])
    df = pd.concat([df, new_record_df], ignore_index=True)
    return df


# READ - View record
def view_record(df, id_column, id_value):
    record = df[df[id_column] == id_value]
    return record

# UPDATE - Edit record
def update_record(df, id_column, id_value, field, new_value):
    df.loc[df[id_column] == id_value, field] = new_value
    return df

# DELETE - Remove record
def delete_record(df, id_column, id_value):
    df = df[df[id_column] != id_value]
    return df

# --------------------------
# Example: Use functions and print output

# 1. View a record (e.g., Claim_ID=5)
print("View record with Claim_ID=5:")
print(view_record(claims_df, 'Claim_ID', 5))

# 2. Add a new record to claims_df
new_claim = {
    'Claim_ID': 1001,
    'Food_ID': 1,
    'Receiver_ID': 1,
    'Status': 'Pending',
    'Timestamp': '8/17/2025 5:03'
}
claims_df = add_record(claims_df, new_claim)
print("\nAdded new record. View Claim_ID=1001:")
print(view_record(claims_df, 'Claim_ID', 1001))

# 3. Update a record (change Status of Claim_ID=1001 to 'Completed')
claims_df = update_record(claims_df, 'Claim_ID', 1001, 'Status', 'Completed')
print("\nUpdated record. View Claim_ID=1001 after update:")
print(view_record(claims_df, 'Claim_ID', 1001))

# 4. Delete a record (remove Claim_ID=1001)
claims_df = delete_record(claims_df, 'Claim_ID', 1001)
print("\nDeleted Claim_ID=1001. Try to view it:")
print(view_record(claims_df, 'Claim_ID', 1001))

"""# Data Analysis -"""

# Upload your dataset
from google.colab import files
uploaded = files.upload()

# Load dataset (replace 'your_file.csv' with actual file name)
df = pd.read_csv("claims_data.csv")
df = pd.read_csv("food_listings_data.csv")
df = pd.read_csv("receivers_data.csv")
df = pd.read_csv("providers_data.csv")
# Quick overview
print(df.info())
print(df.head())

# Data Cleaning and Preprocessing
# Convert expiry date to datetime
food['Expiry_Date'] = pd.to_datetime(food['Expiry_Date'], errors='coerce')

# Check for missing values
print(food.isnull().sum())

# Fill or drop missing values as appropriate
food = food.dropna(subset=['Location', 'Expiry_Date', 'Quantity'])

# Additional cleaning as needed
# 1. Remove duplicate rows
food = food.drop_duplicates()

# 2. Strip whitespace from string columns (if any)
string_cols = ['Food_Name', 'Location', 'Food_Type', 'Meal_Type']
for col in string_cols:
    food[col] = food[col].astype(str).str.strip().str.title()

# 3. Standardize category and location names (e.g., case normalization)
# This was already done in a previous step (Clean String Fields)

# 4. Handle outlier or invalid quantity values
food = food[food['Quantity'] > 0]  # Keep only positive quantities

# 5. Check for invalid expiry dates
# For example, remove dates in the past (if applicable)
today = pd.Timestamp.today()
food = food[food['Expiry_Date'] >= today]

# 6. Reset index after cleaning
food = food.reset_index(drop=True)

# 7. Final missing value check
print(food.isnull().sum())
print(food.head())

# Check all columns
print("Columns in your dataset:")
print(df.columns.tolist())

# Show first 5 rows
print("Sample data:")
print(df.head())

#  Food Wastage Trends by Category
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your dataset
df = pd.read_csv('food_listings_data.csv')  # replace with your file name

# Clean: ensure 'quantity' column is numeric
df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')

# Drop rows with missing Food_Type or quantity
df = df.dropna(subset=['Food_Type', 'Quantity'])
df = df[df['Quantity'] > 0]

# Group and sum quantities by Food_Type
food_type_trends = df.groupby('Food_Type')['Quantity'].sum().reset_index()
print(food_type_trends)  # for verification

# Plot the food wastage trend by food type
plt.figure(figsize=(10, 6))
sns.barplot(x='Food_Type', y='Quantity', data=food_type_trends)
plt.title('Food Wastage by Food Type')
plt.xticks(rotation=45)
plt.xlabel('Food Type')
plt.ylabel('Total Wastage')
plt.tight_layout()
plt.show()

# Food Wastage Trends by Location
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming DataFrame `df` is already loaded as before,
# If not, load it again:
df = pd.read_csv('food_listings_data.csv')

# Clean: ensure 'Q' column is numeric
df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')

# Drop missing / invalid values
df = df.dropna(subset=['Location', 'Quantity'])
df = df[df['Quantity'] > 0]

# Group and sum Q by Location
location_trends = df.groupby('Location')['Quantity'].sum().reset_index()
print(location_trends)  # for verification

# Plot the food wastage trend by Location
plt.figure(figsize=(10, 6))
sns.barplot(x='Location', y='Quantity', data=location_trends)
plt.title('Food Wastage by Location')
plt.xticks(rotation=45)
plt.xlabel('Location')
plt.ylabel('Total Wastage')
plt.tight_layout()
plt.show()

# Food Wastage Trends by Expiery Date
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming food is loaded and cleaned as before
# If not, load it:
food = pd.read_csv('food_listings_data.csv')

# Update these with your actual column names
date_col = 'Expiry_Date'   # Change if your expiry date column has a different name
quantity_col = 'Quantity'  # Quantity column

# Convert expiry_date to datetime
food[date_col] = pd.to_datetime(food[date_col], errors='coerce')

# Drop rows with missing/invalid expiry_date or Quantity
food = food.dropna(subset=[date_col, quantity_col])
food = food[food[quantity_col] > 0]

# Group by expiry_date
expiry_trends = food.groupby(date_col)[quantity_col].sum().reset_index()

print(expiry_trends)  # check your result

# Plot food wastage by expiry date
plt.figure(figsize=(12, 6))
sns.lineplot(x=date_col, y=quantity_col, data=expiry_trends, marker='o')
plt.title('Food Wastage by Expiry Date')
plt.xlabel('Expiry Date')
plt.ylabel('Total Wastage')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# ●	Generate reports for effective food distribution.
# Assuming df is loaded and cleaned
df = pd.read_csv('food_listings_data.csv')
# Create a summary pivot table
summary_report = df.pivot_table(
    index='Location',
    columns='Food_Type',
    values='Quantity',
    aggfunc='sum',
    fill_value=0
)
print(summary_report)

# Top locations with highest wastage
top_locations = df.groupby('Location')['Quantity'].sum().sort_values(ascending=False)
print("Top locations with food wastage:\n", top_locations)

# Top food types with highest wastage
top_food_types = df.groupby('Food_Type')['Quantity'].sum().sort_values(ascending=False)
print("Top food types with food wastage:\n", top_food_types)

# Ensure expiry_date is datetime
df['Expiry_Date'] = pd.to_datetime(df['Expiry_Date'], errors='coerce')

# Find foods expiring soon (next 7 days)
from datetime import timedelta

soon = datetime.today() + timedelta(days=7)
near_expiry = df[df['Expiry_Date'] <= soon].sort_values('Expiry_Date')
print("Foods expiring in next 7 days:\n", near_expiry[['Food_Type', 'Location', 'Quantity', 'Expiry_Date']])

summary_report.to_csv('food_distribution_summary.csv')
top_locations.to_csv('top_locations.csv', header=True)
top_food_types.to_csv('top_food_types.csv', header=True)
near_expiry.to_csv('near_expiry_foods.csv', index=False)

"""# Food Providers & Receivers
1.	How many food providers and receivers are there in each city?
2.	Which type of food provider (restaurant, grocery store, etc.) contributes the most food?
3.	What is the contact information of food providers in a specific city?
4.	Which receivers have claimed the most food?

"""

# Load Datset
from google.colab import files
upload = files.upload()
providers_df = pd.read_csv('providers_data.csv')
receivers_df = pd.read_csv('receivers_data.csv')

# Group by city and count providers and receivers
providers_count = providers_df.groupby('City')['Provider_ID'].nunique().reset_index(name='num_providers')
receivers_count = receivers_df.groupby('City')['Receiver_ID'].nunique().reset_index(name='num_receivers')

# Merge counts by city for single view
city_counts = pd.merge(providers_count, receivers_count, on='City', how='outer').fillna(0)

print(city_counts)

# Merge providers with food_listings to get food quantity per provider type
providers_food = pd.merge(providers_df, food, on='Provider_ID', how='left')

# Aggregate total food contribution by provider type
# Use the correct column name 'Type' from providers_df
contribution_by_type = providers_food.groupby('Type')['Quantity'].sum().reset_index()

# Find the provider type with maximum total contribution
max_contributor = contribution_by_type.loc[contribution_by_type['Quantity'].idxmax()]

print(f"Top contributing provider type: {max_contributor['Type']} with quantity {max_contributor['Quantity']}")

# Specify city
city_name = 'New Jessica'  # Example city

# Filter providers in that city and select relevant contact columns
contacts = providers_df.loc[providers_df['City'] == city_name, ['Name', 'Contact']]

print(contacts)

# Merge claims with food_listings to get food quantity for each claim
claims_food = pd.merge(claims, food, on='Food_ID', how='left')

# Merge with receivers to link claims to receivers
claims_food_receivers = pd.merge(claims_food, receivers_df, on='Receiver_ID', how='left')

# Filter for completed claims and group by receiver name to sum quantity
claimed_by_receiver = claims_food_receivers[claims_food_receivers['Status'] == 'Completed'].groupby('Name')['Quantity'].sum().reset_index()

# Sort receivers by quantity claimed descending
top_receivers = claimed_by_receiver.sort_values(by='Quantity', ascending=False)

print("Top receivers by food claimed:")
print(top_receivers.head())

"""# Food Listings & Availability
5.	What is the total quantity of food available from all providers?
6.	Which city has the highest number of food listings?
7.	What are the most commonly available food types

"""

import pandas as pd

# The quantity information is in the 'food' DataFrame, not 'providers_df'
# Sum the 'Quantity' column in the 'food' DataFrame
total_quantity = food['Quantity'].sum()
print(f"Total quantity of food available from all providers: {total_quantity}")

# Assuming food DataFrame has a 'Location' column for listings
listings_by_city = food.groupby('Location').size().reset_index(name='num_listings')
top_city = listings_by_city.loc[listings_by_city['num_listings'].idxmax()]

print(f"City with highest number of food listings: {top_city['Location']} ({top_city['num_listings']} listings)")

# Assuming food DataFrame has a 'Food_Type' column
food_type_counts = food['Food_Type'].value_counts().reset_index()
food_type_counts.columns = ['food_type', 'count']

print("Most commonly available food types:")
print(food_type_counts.head(10))  # Top 10 food types

"""# Claims & Distribution
       8. How many food claims have been made for each food item?
       9. Which provider has had the highest number of successful food claims?
      10. What percentage of food claims are completed vs. pending vs. canceled?

"""

# Count claims per food item
claims_per_item = claims_df.merge(food, on='Food_ID', how='left').groupby('Food_Name').size().reset_index(name='num_claims')

print(claims_per_item)

# Filter for completed claims
completed_claims = claims_df[claims_df['Status'] == 'Completed']

# Merge completed claims with food and providers to link claims to providers
completed_claims_providers = completed_claims.merge(food, on='Food_ID', how='left').merge(providers_df, on='Provider_ID', how='left')

# Count completed claims by provider name
completed_by_provider = completed_claims_providers.groupby('Name')['Claim_ID'].count().reset_index(name='completed_claims')

# Get provider with max completed claims
top_provider = completed_by_provider.loc[completed_by_provider['completed_claims'].idxmax()]

print(f"Provider with highest number of successful claims: {top_provider['Name']} ({top_provider['completed_claims']} claims)")

# Count claims by status
status_counts = claims_df['Status'].value_counts(normalize=True).mul(100).reset_index()
status_counts.columns = ['claim_status', 'percentage']

print("Percentage of food claims by status:")
print(status_counts)

"""# Analysis & Insights
11. What is the average quantity of food claimed per receiver?
12. Which meal type (breakfast, lunch, dinner, snacks) is claimed the most?
13.	What is the total quantity of food donated by each provider?

"""

# Calculate average quantity claimed per receiver
# Merge claims with food to get the quantity for each claim
claims_with_quantity = claims_df.merge(food, on='Food_ID', how='left')

# Group by Receiver_ID and calculate the mean of the Quantity
avg_quantity_per_receiver = claims_with_quantity.groupby('Receiver_ID')['Quantity'].mean().reset_index(name='avg_quantity_claimed')

print(avg_quantity_per_receiver)

# Sum quantity claimed by meal type
# Merge claims with food to get meal type and quantity
claims_with_meal_quantity = claims_df.merge(food, on='Food_ID', how='left')

# Group by Meal_Type and sum the Quantity
quantity_by_meal = claims_with_meal_quantity.groupby('Meal_Type')['Quantity'].sum().reset_index()

# Find meal type with maximum quantity claimed
top_meal_type = quantity_by_meal.loc[quantity_by_meal['Quantity'].idxmax()]

print(f"Meal type claimed the most: {top_meal_type['Meal_Type']} with quantity {top_meal_type['Quantity']}")

# Merge claims with food to get the quantity for each claim
claims_with_quantity = claims_df.merge(food, on='Food_ID', how='left')

# Merge with providers to link claims to providers
claims_with_provider = claims_with_quantity.merge(providers_df, on='Provider_ID', how='left')

# Sum quantity claimed grouped by provider name to get donated quantity per provider
total_donated_by_provider = claims_with_provider.groupby('Name')['Quantity'].sum().reset_index(name='total_quantity_donated')

print(total_donated_by_provider)